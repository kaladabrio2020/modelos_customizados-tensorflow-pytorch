{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import *\n",
    "import printing_train as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.california_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = train\n",
    "xtest , ytest  = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_ = (xtrain - xtrain.mean(0))/xtrain.std(0)\n",
    "xtest_ = (xtest - xtest.mean(0))/xtest.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_ = np.log1p(ytrain).reshape(-1, 1)\n",
    "ytest_ = np.log1p(ytest).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo(x, weights, bias):\n",
    "    return tf.matmul(a=x, b=weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_.shape[0]//20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definido o data\n",
    "data = tf.data.Dataset.from_tensor_slices((xtrain_, ytrain_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(8,), dtype=tf.float32, name=None), TensorSpec(shape=(1,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definindo loss, optim ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = data\\\n",
    "            .batch( batch_size=825, drop_remainder=True)\\\n",
    "            .shuffle(buffer_size=10, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelRegression:\n",
    "    def __init__(self, seed = 32, shape = None, optim=keras.optimizers.SGD(), losses=keras.losses.mean_squared_error, metrics=[]):\n",
    "        # Inicializando os pesos aleatoriamente\n",
    "        rand_ = np.random.RandomState(seed=seed)\n",
    "        self.norm_ = rand_.normal(0, 1, size=shape).reshape(-1, 1)\n",
    "\n",
    "        # optimizer e função de perda\n",
    "        self.optim = optim\n",
    "        self.losses = losses\n",
    "\n",
    "        # metricas \n",
    "        self.metrics = { m.__name__ : m for m in metrics }\n",
    "\n",
    "\n",
    "    # X @ w.t + b\n",
    "    def model_(self, x): \n",
    "        return tf.matmul(x, self.weights) + self.bias\n",
    "    \n",
    "    def fit(self, train, n_epochs = 5, verbose=False):\n",
    "    \n",
    "        self.tam_ = len(train_)\n",
    "        \n",
    "        # Inicializando os pesos e bias\n",
    "        self.weights = tf.Variable( self.norm_, dtype=tf.float32 )\n",
    "        self.bias    = tf.Variable([0], dtype=tf.float32 )\n",
    "        \n",
    "        for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "            for enum, (xbatch, ybatch) in enumerate(train, start=1):\n",
    "                # Fazendo predição\n",
    "                with tf.GradientTape() as tape:\n",
    "                    pred_ = self.model_(xbatch)\n",
    "                    loss_ = tf.reduce_mean(self.losses(ybatch, pred_))\n",
    "\n",
    "                # Atualiza os pesos\n",
    "                gradient = tape.gradient(loss_, [self.weights, self.bias])\n",
    "                self.optim.apply_gradients(\n",
    "                    zip(gradient, [self.weights, self.bias])\n",
    "                )\n",
    "                        \n",
    "    # função de predição\n",
    "    def predict(self, x): return self.model_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelRegression(\n",
    "    seed  = 44,\n",
    "    optim = keras.optimizers.SGD(learning_rate=0.01),\n",
    "    losses= keras.losses.mean_squared_error,\n",
    "    shape = xtrain.shape[1],\n",
    "    metrics = [\n",
    "        keras.metrics.mean_absolute_error\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train=train_, n_epochs=100, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xtrain_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(55716.79)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.expm1(ytrain_.reshape(-1, 1)), np.expm1(pred.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31349098682403564"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(np.expm1(ytrain_.reshape(-1, 1)), np.expm1(pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = (X / 255.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ =  tf.one_hot(y, 10, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelClassificationMulticlass:\n",
    "    def __init__(self, seed = 32, shape = 3, \n",
    "                 optim  = keras.optimizers.SGD(), \n",
    "                 losses = keras.losses.mean_squared_error,\n",
    "                 activation = keras.activations.softmax,\n",
    "                 metrics=[]):\n",
    "        # Inicializando os pesos aleatoriamente\n",
    "        rand_ = np.random.RandomState(seed=seed)\n",
    "        self.norm_ = rand_.normal(0, 2, size=(shape, shape))\n",
    "\n",
    "        # optimizer e função de perda\n",
    "        self.optim = optim\n",
    "        self.losses = losses\n",
    "        # função de ativação\n",
    "        self.activation = activation        \n",
    "        # metricas \n",
    "        self.metrics = { m.__name__ : m for m in metrics }\n",
    "\n",
    "\n",
    "    # X @ w.t + b\n",
    "    def model_(self, x):\n",
    "        return tf.matmul(x, self.weights) + self.bias\n",
    "    \n",
    "    def fit(self, train, n_epochs = 5, verbose=False):\n",
    "        self.tam_ = len(train_)\n",
    "        # Inicializando os pesos e bias\n",
    "        self.weights = tf.Variable( self.norm_, dtype=tf.float32 )\n",
    "        self.bias    = tf.Variable([0], dtype=tf.float32 )\n",
    "        \n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            self.metric_ = {}\n",
    "\n",
    "            for enum, (xbatch, ybatch) in enumerate(train, start=1):\n",
    "                # Fazendo predição\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    pred_ = self.activation(self.model_(xbatch))\n",
    "                    loss_ = tf.reduce_mean(self.losses(ybatch, pred_))\n",
    "\n",
    "                # Atualiza os pesos\n",
    "                gradient = tape.gradient(loss_, [self.weights, self.bias])\n",
    "                self.optim.apply_gradients(\n",
    "                    zip(gradient, [self.weights, self.bias])\n",
    "                )\n",
    "\n",
    "                # imprimi os resultados durante treinamento\n",
    "                if verbose:\n",
    "                    if n_epochs > 20: \n",
    "                        if epoch % 10 == 0:\n",
    "                            self.print_(ybatch, pred_, epoch, n_epochs, enum)\n",
    "                    else:\n",
    "                        self.print_(ybatch, pred_, epoch, n_epochs, enum)\n",
    "                        \n",
    "    # função de predição\n",
    "    def predict(self, x): return self.model_(x)\n",
    "\n",
    "    def print_(self, ybatch, pred_, epoch, n_epochs, enum):\n",
    "        for keys, values in self.metrics.items():\n",
    "            self.metric_[keys] = tf.reduce_mean(values(ybatch, pred_))\n",
    "        pt.print_progress(epoch, n_epochs, enum, self.tam_, self.metric_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices((X_, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = data\\\n",
    "            .batch( batch_size = 1000)\\\n",
    "            .shuffle( buffer_size=10, seed=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodelClassification\u001b[49m(shape\u001b[38;5;241m=\u001b[39mX_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model = modelClassification(shape=X_.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train = train_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
